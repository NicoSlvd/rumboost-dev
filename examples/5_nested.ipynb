{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rumboost.rumboost import rum_train\n",
    "from rumboost.datasets import load_preprocess_LPMC\n",
    "from rumboost.metrics import cross_entropy\n",
    "\n",
    "import lightgbm\n",
    "import hyperopt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Nested logit model (correlation amongst alternatives)\n",
    "\n",
    "This notebook shows features implemented in RUMBoost through an example on the LPMC dataset, a mode choice dataset in London developed Hillel et al. (2018). You can find the original source of data [here](https://www.icevirtuallibrary.com/doi/suppl/10.1680/jsmic.17.00018) and the original paper [here](https://www.icevirtuallibrary.com/doi/full/10.1680/jsmic.17.00018).\n",
    "\n",
    "We first load the preprocessed dataset and its folds for cross-validation. You can find the data under the Data folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load dataset\n",
    "LPMC_train, LPMC_test, folds = load_preprocess_LPMC(path=\"../Data/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Logit model\n",
    "\n",
    "We relax the assumption that the error term is distributed i.i.d.. If we assume that alternatives are correlated, we obtain a nested logit-like model. Nested logit probabilities are implemented in RUMBoost. The additional parameter, the scale of a nest $\\mu$, can be estimated with two ways:\n",
    "1. by a hyperparameter search\n",
    "2. optimised within the trianing loop\n",
    "\n",
    "Training a nested logit-like rumboost model requires an additional dictionary in the model specification dictionary. The nested logit disctionary follows the following form:\n",
    "\n",
    "- ```mu```: a list containing the values (as float) of mu for each nest, e.g. ```[mu_nest_0, mu_nest_1]```\n",
    "- ```nests```: a dictionary representing the nesting structure. Keys are the nests id, and values are the the list of alternatives in the corresponding nest. For example {0: [0, 1], 1: [2, 3]} means that alternative 0 and 1 are in nest 0, and alternative 2 and 3 are in nest 1.\n",
    "- `optimise_mu`: a boolean or list of boolean. If it is a simple boolean and True, all mu values are found through scipy.minimize. If it is a list of boolean, it should be the same size than `mu` and it represents which value should be optimised or not.\n",
    "  \n",
    "In this example, we assume that PT and car are in a 'motorised' nest, while the walking and cycling alternative are in their own nests."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General parameters\n",
    "\n",
    "You can find an example of general parameters below. Unless stated otherwise, the parameters are the same than in LightGBM, since these parameters are applied directly to LightGBM Booster objects. You can find more information in the LightGBM [docs](https://lightgbm.readthedocs.io/en/stable/Parameters.html#).  For a simple RUMBoost, we recommend letting most of the parameters with default values, as RUMBoost is less sensitive to overfitting. **For a multiclass classification problem, you need to specify the num_classes parameter with the appropriate number of classes**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "general_params = {\n",
    "    \"n_jobs\": -1,\n",
    "    \"num_classes\": 4,  # important\n",
    "    \"verbosity\": 1,  # specific RUMBoost parameter\n",
    "    \"num_iterations\": 3000,\n",
    "    \"early_stopping_round\": 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Utility Model structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rum_structure = [\n",
    "    {\n",
    "        \"utility\": [0],\n",
    "        \"variables\": [\n",
    "            \"age\",\n",
    "            \"female\",\n",
    "            \"day_of_week\",\n",
    "            \"start_time_linear\",\n",
    "            \"car_ownership\",\n",
    "            \"driving_license\",\n",
    "            \"purpose_B\",\n",
    "            \"purpose_HBE\",\n",
    "            \"purpose_HBO\",\n",
    "            \"purpose_HBW\",\n",
    "            \"purpose_NHBO\",\n",
    "            \"fueltype_Average\",\n",
    "            \"fueltype_Diesel\",\n",
    "            \"fueltype_Hybrid\",\n",
    "            \"fueltype_Petrol\",\n",
    "            \"distance\",\n",
    "            \"dur_walking\",\n",
    "        ],\n",
    "        \"boosting_params\": {\n",
    "            \"monotone_constraints_method\": \"advanced\",\n",
    "            \"max_depth\": 1,\n",
    "            \"n_jobs\": -1,\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"monotone_constraints\": [\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                -1,\n",
    "                -1,\n",
    "            ],\n",
    "            \"interaction_constraints\": [\n",
    "                [0],\n",
    "                [1],\n",
    "                [2],\n",
    "                [3],\n",
    "                [4],\n",
    "                [5],\n",
    "                [6],\n",
    "                [7],\n",
    "                [8],\n",
    "                [9],\n",
    "                [10],\n",
    "                [11],\n",
    "                [12],\n",
    "                [13],\n",
    "                [14],\n",
    "                [15],\n",
    "                [16],\n",
    "            ],\n",
    "        },\n",
    "        \"shared\": False,\n",
    "    },\n",
    "    {\n",
    "        \"utility\": [1],\n",
    "        \"variables\": [\n",
    "            \"age\",\n",
    "            \"female\",\n",
    "            \"day_of_week\",\n",
    "            \"start_time_linear\",\n",
    "            \"car_ownership\",\n",
    "            \"driving_license\",\n",
    "            \"purpose_B\",\n",
    "            \"purpose_HBE\",\n",
    "            \"purpose_HBO\",\n",
    "            \"purpose_HBW\",\n",
    "            \"purpose_NHBO\",\n",
    "            \"fueltype_Average\",\n",
    "            \"fueltype_Diesel\",\n",
    "            \"fueltype_Hybrid\",\n",
    "            \"fueltype_Petrol\",\n",
    "            \"distance\",\n",
    "            \"dur_cycling\",\n",
    "        ],\n",
    "        \"boosting_params\": {\n",
    "            \"monotone_constraints_method\": \"advanced\",\n",
    "            \"max_depth\": 1,\n",
    "            \"n_jobs\": -1,\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"monotone_constraints\": [\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                -1,\n",
    "                -1,\n",
    "            ],\n",
    "            \"interaction_constraints\": [\n",
    "                [0],\n",
    "                [1],\n",
    "                [2],\n",
    "                [3],\n",
    "                [4],\n",
    "                [5],\n",
    "                [6],\n",
    "                [7],\n",
    "                [8],\n",
    "                [9],\n",
    "                [10],\n",
    "                [11],\n",
    "                [12],\n",
    "                [13],\n",
    "                [14],\n",
    "                [15],\n",
    "                [16],\n",
    "            ],\n",
    "        },\n",
    "        \"shared\": False,\n",
    "    },\n",
    "    {\n",
    "        \"utility\": [2],\n",
    "        \"variables\": [\n",
    "            \"age\",\n",
    "            \"female\",\n",
    "            \"day_of_week\",\n",
    "            \"start_time_linear\",\n",
    "            \"car_ownership\",\n",
    "            \"driving_license\",\n",
    "            \"purpose_B\",\n",
    "            \"purpose_HBE\",\n",
    "            \"purpose_HBO\",\n",
    "            \"purpose_HBW\",\n",
    "            \"purpose_NHBO\",\n",
    "            \"fueltype_Average\",\n",
    "            \"fueltype_Diesel\",\n",
    "            \"fueltype_Hybrid\",\n",
    "            \"fueltype_Petrol\",\n",
    "            \"distance\",\n",
    "            \"dur_pt_access\",\n",
    "            \"dur_pt_bus\",\n",
    "            \"dur_pt_rail\",\n",
    "            \"dur_pt_int_waiting\",\n",
    "            \"dur_pt_int_walking\",\n",
    "            \"pt_n_interchanges\",\n",
    "            \"cost_transit\",\n",
    "        ],\n",
    "        \"boosting_params\": {\n",
    "            \"monotone_constraints_method\": \"advanced\",\n",
    "            \"max_depth\": 1,\n",
    "            \"n_jobs\": -1,\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"monotone_constraints\": [\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                -1,\n",
    "                -1,\n",
    "                -1,\n",
    "                -1,\n",
    "                -1,\n",
    "                -1,\n",
    "                -1,\n",
    "                -1,\n",
    "            ],\n",
    "            \"interaction_constraints\": [\n",
    "                [0],\n",
    "                [1],\n",
    "                [2],\n",
    "                [3],\n",
    "                [4],\n",
    "                [5],\n",
    "                [6],\n",
    "                [7],\n",
    "                [8],\n",
    "                [9],\n",
    "                [10],\n",
    "                [11],\n",
    "                [12],\n",
    "                [13],\n",
    "                [14],\n",
    "                [15],\n",
    "                [16],\n",
    "                [17],\n",
    "                [18],\n",
    "                [19],\n",
    "                [20],\n",
    "                [21],\n",
    "                [22],\n",
    "            ],\n",
    "        },\n",
    "        \"shared\": False,\n",
    "    },\n",
    "    {\n",
    "        \"utility\": [3],\n",
    "        \"variables\": [\n",
    "            \"age\",\n",
    "            \"female\",\n",
    "            \"day_of_week\",\n",
    "            \"start_time_linear\",\n",
    "            \"car_ownership\",\n",
    "            \"driving_license\",\n",
    "            \"purpose_B\",\n",
    "            \"purpose_HBE\",\n",
    "            \"purpose_HBO\",\n",
    "            \"purpose_HBW\",\n",
    "            \"purpose_NHBO\",\n",
    "            \"fueltype_Average\",\n",
    "            \"fueltype_Diesel\",\n",
    "            \"fueltype_Hybrid\",\n",
    "            \"fueltype_Petrol\",\n",
    "            \"distance\",\n",
    "            \"dur_driving\",\n",
    "            \"cost_driving_fuel\",\n",
    "            \"congestion_charge\",\n",
    "            \"driving_traffic_percent\",\n",
    "        ],\n",
    "        \"boosting_params\": {\n",
    "            \"monotone_constraints_method\": \"advanced\",\n",
    "            \"max_depth\": 1,\n",
    "            \"n_jobs\": -1,\n",
    "            \"learning_rate\": 0.1,\n",
    "            \"monotone_constraints\": [\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                0,\n",
    "                -1,\n",
    "                -1,\n",
    "                -1,\n",
    "                -1,\n",
    "                -1,\n",
    "            ],\n",
    "            \"interaction_constraints\": [\n",
    "                [0],\n",
    "                [1],\n",
    "                [2],\n",
    "                [3],\n",
    "                [4],\n",
    "                [5],\n",
    "                [6],\n",
    "                [7],\n",
    "                [8],\n",
    "                [9],\n",
    "                [10],\n",
    "                [11],\n",
    "                [12],\n",
    "                [13],\n",
    "                [14],\n",
    "                [15],\n",
    "                [16],\n",
    "                [17],\n",
    "                [18],\n",
    "                [19],\n",
    "            ],\n",
    "        },\n",
    "        \"shared\": False,\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### $\\mu$ hyperparameter search\n",
    "\n",
    "We treat $\\mu$ as a hyperparameter. We use hyperopt to find the optimal value of the hyperparameter. More details on how to use hyperopt [here](https://hyperopt.github.io/hyperopt/).\n",
    "\n",
    "Note that for computational purposes, we show here a hyperparameter search for one iteration. As an example, we ran 25 iterations to obtain the results of the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify nest\n",
    "nest = {0: [0], 1: [1], 2: [2, 3]}\n",
    "\n",
    "nested_structure = {\n",
    "    \"mu\": np.array([1, 1, 1.17]),\n",
    "    \"nests\": nest,\n",
    "    \"optimise_mu\": False,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model specification\n",
    "model_specification = {\n",
    "    \"general_params\": general_params,\n",
    "    \"rum_structure\": rum_structure,\n",
    "    \"nested_logit\": nested_structure,\n",
    "}\n",
    "\n",
    "#features and label column names\n",
    "features = [f for f in LPMC_train.columns if f != \"choice\"]\n",
    "label = \"choice\"\n",
    "\n",
    "#create lightgbm dataset\n",
    "lgb_train_set = lightgbm.Dataset(LPMC_train[features], label=LPMC_train[label], free_raw_data=False)\n",
    "lgb_test_set = lightgbm.Dataset(LPMC_test[features], label=LPMC_test[label], free_raw_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#specifiy seach of mu\n",
    "param_space =  {'mu': hyperopt.hp.uniform('mu', 1, 2)}\n",
    "\n",
    "#objective for hyperopt\n",
    "def objective(space):\n",
    "\n",
    "    #create mu structure\n",
    "    nested_structure[\"mu\"] = np.array([1, 1, space[\"mu\"]])\n",
    "\n",
    "    ce_loss = 0\n",
    "    num_trees = 0\n",
    "\n",
    "    for train_idx, test_idx in folds:\n",
    "        train_set = lgb_train_set.subset(sorted(train_idx))\n",
    "        test_set = lgb_train_set.subset(sorted(test_idx))\n",
    "\n",
    "        LPMC_model_trained = rum_train(train_set, model_specification, valid_sets=[test_set])\n",
    "\n",
    "        ce_loss += LPMC_model_trained.best_score\n",
    "        num_trees += LPMC_model_trained.best_iteration\n",
    "\n",
    "\n",
    "    ce_loss = ce_loss / 5\n",
    "    num_trees = num_trees / 5\n",
    "\n",
    "    return {'loss': ce_loss, 'status': hyperopt.STATUS_OK, 'best_iteration': num_trees}\n",
    "\n",
    "\n",
    "#%%\n",
    "#n_iter=25\n",
    "n_iter = 1\n",
    "\n",
    "trials = hyperopt.Trials()\n",
    "best_classifier = hyperopt.fmin(fn=objective,\n",
    "                                space=param_space,\n",
    "                                algo=hyperopt.tpe.suggest,\n",
    "                                max_evals=n_iter,\n",
    "                                trials=trials)\n",
    "\n",
    "print(f'Best mu: {best_classifier[\"mu\"]} \\n Best negative CE: {trials.best_trial[\"result\"][\"loss\"]}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-Validation\n",
    "\n",
    "Once we know the optimal value of $\\mu$, we can perform cross-validation to obtain the best number of trees.\n",
    "\n",
    "Note that we use the optimal value of $\\mu$ found with a bigger hyperparameter search, i.e. 1.17."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, folds = load_preprocess_LPMC(path=\"../Data/\")\n",
    "\n",
    "#optimal mu\n",
    "nested_structure['mu'] = np.array([1., 1., 1.166746773143513])\n",
    "\n",
    "ce_loss = 0\n",
    "num_trees = 0\n",
    "\n",
    "#CV with 5 folds\n",
    "for i, (train_idx, test_idx) in enumerate(folds):\n",
    "\n",
    "    #create the lightgbm CV training and validation set\n",
    "    train_set = lgb_train_set.subset(sorted(train_idx))\n",
    "    test_set = lgb_train_set.subset(sorted(test_idx))\n",
    "    \n",
    "    print('-'*50 + '\\n')\n",
    "    print(f'Iteration {i+1}')\n",
    "\n",
    "    #train the model with rum_train and nest parameters\n",
    "    LPMC_model_trained = rum_train(train_set, model_specification, valid_sets = [test_set])\n",
    "\n",
    "    #aggregate results\n",
    "    ce_loss += LPMC_model_trained.best_score\n",
    "    num_trees += LPMC_model_trained.best_iteration\n",
    "    print('-'*50 + '\\n')\n",
    "    print(f'Best cross entropy loss: {LPMC_model_trained.best_score}')\n",
    "    print(f'Best number of trees: {LPMC_model_trained.best_iteration}')\n",
    "\n",
    "ce_loss = ce_loss/5\n",
    "num_trees = num_trees/5\n",
    "print('-'*50 + '\\n')\n",
    "print(f'Cross validation negative cross entropy loss: {ce_loss}')\n",
    "print(f'With a number of trees on average of {num_trees}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model on out-of-sample data\n",
    "\n",
    "Now that we have the optimal number of trees (1243), we can train the final version of the model on the full dataset, and test it on out-of-sample data with the ```predict()``` function. Note that the dataset must be a lightgbm object in the ```predict()``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_params['num_iterations'] = int(num_trees)\n",
    "general_params['early_stopping_round'] = None \n",
    "\n",
    "LPMCnested_model_fully_trained = rum_train(lgb_train_set, model_specification)\n",
    "\n",
    "preds = LPMCnested_model_fully_trained.predict(lgb_test_set)\n",
    "\n",
    "ce_test = cross_entropy(preds, lgb_test_set.get_label().astype(int))\n",
    "\n",
    "print('-'*50)\n",
    "print(f'Final negative cross-entropy on the test set: {ce_test}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimising $\\mu$ with `scipy.minimize`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify nest\n",
    "nest = {0: [0], 1: [1], 2: [2, 3]}\n",
    "\n",
    "nested_structure = {\n",
    "    \"mu\": np.array([1., 1., 1.25]),\n",
    "    \"nests\": nest,\n",
    "    \"optimise_mu\": [False, False, True],\n",
    "    \"optim_interval\": 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, folds = load_preprocess_LPMC(path=\"../Data/\")\n",
    "\n",
    "#model specification\n",
    "model_specification = {\n",
    "    \"general_params\": general_params,\n",
    "    \"rum_structure\": rum_structure,\n",
    "    \"nested_logit\": nested_structure,\n",
    "}\n",
    "\n",
    "#features and label column names\n",
    "features = [f for f in LPMC_train.columns if f != \"choice\"]\n",
    "label = \"choice\"\n",
    "\n",
    "#create lightgbm dataset\n",
    "lgb_train_set = lightgbm.Dataset(LPMC_train[features], label=LPMC_train[label], free_raw_data=False)\n",
    "lgb_test_set = lightgbm.Dataset(LPMC_test[features], label=LPMC_test[label], free_raw_data=False)\n",
    "\n",
    "ce_loss = []\n",
    "num_trees = 0\n",
    "optimised_mu = []\n",
    "\n",
    "for train_idx, test_idx in folds:\n",
    "    train_set = lgb_train_set.subset(sorted(train_idx))\n",
    "    test_set = lgb_train_set.subset(sorted(test_idx))\n",
    "\n",
    "    LPMC_model_trained = rum_train(train_set, model_specification, valid_sets=[test_set])\n",
    "\n",
    "    ce_loss.append(LPMC_model_trained.best_score)\n",
    "    num_trees += LPMC_model_trained.best_iteration\n",
    "    optimised_mu.append(LPMC_model_trained.mu)\n",
    "\n",
    "num_trees = num_trees / 5\n",
    "\n",
    "for i, mu in enumerate(optimised_mu):\n",
    "    print(f\"iteration {i} --- optimised mu: {mu}, CE: {ce_loss[i]}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing the model on out-of-sample data\n",
    "\n",
    "Now that we have the optimal number of trees, we can train the final version of the model on the full dataset, and test it on out-of-sample data with the ```predict()``` function. Note that the dataset must be a lightgbm object in the ```predict()``` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_params['num_iterations'] = int(num_trees)\n",
    "general_params['early_stopping_round'] = None\n",
    "\n",
    "LPMCnested_model_fully_trained = rum_train(lgb_train_set, model_specification)\n",
    "\n",
    "preds = LPMCnested_model_fully_trained.predict(lgb_test_set)\n",
    "\n",
    "ce_test = cross_entropy(preds, lgb_test_set.get_label().astype(int))\n",
    "\n",
    "print('-'*50)\n",
    "print(f'Final negative cross-entropy on the test set: {ce_test}')\n",
    "print(f'Opimal mu {LPMCnested_model_fully_trained.mu}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "Salvadé, N., & Hillel, T. (2025). Rumboost: Gradient Boosted Random Utility Models. *Transportation Research Part C: Emerging Technologies* 170, 104897. DOI: [10.1016/j.trc.2024.104897](https://doi.org/10.1016/j.trc.2024.104897)\n",
    "\n",
    "Hillel, T., Elshafie, M.Z.E.B., Jin, Y., 2018. Recreating passenger mode choice-sets for transport simulation: A case study of London, UK. Proceedings of the Institution of Civil Engineers - Smart Infrastructure and Construction 171, 29–42. https://doi.org/10.1680/jsmic.17.00018"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rumb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
